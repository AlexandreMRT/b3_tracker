"""
MÃ³dulo para exportar dados para CSV e JSON
"""
import os
import json
import csv
from datetime import datetime, date
from typing import Optional
from sqlalchemy import func

from database import SessionLocal
from models import Asset, Quote


EXPORTS_PATH = os.environ.get("EXPORTS_PATH", "/app/exports")


def get_latest_quotes(db, quote_date: Optional[date] = None):
    """
    ObtÃ©m as cotaÃ§Ãµes mais recentes de todos os ativos
    Se quote_date for fornecido, busca cotaÃ§Ãµes dessa data especÃ­fica
    """
    if quote_date:
        target_date = datetime.combine(quote_date, datetime.min.time())
        quotes = db.query(Quote).join(Asset).filter(
            Quote.quote_date == target_date
        ).all()
    else:
        # Subquery para pegar a Ãºltima cotaÃ§Ã£o de cada ativo
        subquery = db.query(
            Quote.asset_id,
            func.max(Quote.quote_date).label('max_date')
        ).group_by(Quote.asset_id).subquery()
        
        quotes = db.query(Quote).join(
            subquery,
            (Quote.asset_id == subquery.c.asset_id) & 
            (Quote.quote_date == subquery.c.max_date)
        ).all()
    
    return quotes


def format_change(value: Optional[float]) -> str:
    """Formata uma variaÃ§Ã£o percentual com sinal e cores ANSI"""
    if value is None:
        return "N/A"
    sign = "+" if value >= 0 else ""
    return f"{sign}{value:.2f}%"


def format_quote_row(quote: Quote) -> dict:
    """Formata uma cotaÃ§Ã£o para exportaÃ§Ã£o"""
    return {
        "ticker": quote.asset.ticker.replace(".SA", ""),
        "nome": quote.asset.name,
        "setor": quote.asset.sector,
        "tipo": quote.asset.asset_type,
        "preco_brl": round(quote.price_brl, 2),
        "preco_usd": round(quote.price_usd, 2) if quote.price_usd else None,
        "abertura": round(quote.open_price, 2) if quote.open_price else None,
        "maxima": round(quote.high_price, 2) if quote.high_price else None,
        "minima": round(quote.low_price, 2) if quote.low_price else None,
        "volume": quote.volume,
        # VariaÃ§Ãµes histÃ³ricas
        "var_1d": round(quote.change_1d, 2) if quote.change_1d else None,
        "var_1w": round(quote.change_1w, 2) if quote.change_1w else None,
        "var_1m": round(quote.change_1m, 2) if quote.change_1m else None,
        "var_ytd": round(quote.change_ytd, 2) if quote.change_ytd else None,
        "var_5y": round(quote.change_5y, 2) if quote.change_5y else None,
        "var_all": round(quote.change_all, 2) if quote.change_all else None,
        # PreÃ§os histÃ³ricos
        "preco_1d_ago": round(quote.price_1d_ago, 2) if quote.price_1d_ago else None,
        "preco_1w_ago": round(quote.price_1w_ago, 2) if quote.price_1w_ago else None,
        "preco_1m_ago": round(quote.price_1m_ago, 2) if quote.price_1m_ago else None,
        "preco_inicio_ano": round(quote.price_ytd, 2) if quote.price_ytd else None,
        "preco_5y_ago": round(quote.price_5y_ago, 2) if quote.price_5y_ago else None,
        "preco_all_time": round(quote.price_all_time, 2) if quote.price_all_time else None,
        # Fundamental data
        "market_cap": quote.market_cap,
        "pe_ratio": round(quote.pe_ratio, 2) if quote.pe_ratio else None,
        "forward_pe": round(quote.forward_pe, 2) if quote.forward_pe else None,
        "pb_ratio": round(quote.pb_ratio, 2) if quote.pb_ratio else None,
        "dividend_yield": round(quote.dividend_yield, 2) if quote.dividend_yield else None,
        "eps": round(quote.eps, 2) if quote.eps else None,
        # Risk metrics
        "beta": round(quote.beta, 2) if quote.beta else None,
        "week_52_high": round(quote.week_52_high, 2) if quote.week_52_high else None,
        "week_52_low": round(quote.week_52_low, 2) if quote.week_52_low else None,
        "pct_from_52w_high": round(quote.pct_from_52w_high, 2) if quote.pct_from_52w_high else None,
        # Technical indicators
        "ma_50": round(quote.ma_50, 2) if quote.ma_50 else None,
        "ma_200": round(quote.ma_200, 2) if quote.ma_200 else None,
        "rsi_14": round(quote.rsi_14, 1) if quote.rsi_14 else None,
        "above_ma_50": quote.above_ma_50,
        "above_ma_200": quote.above_ma_200,
        "ma_50_above_200": quote.ma_50_above_200,
        # Financial health
        "profit_margin": round(quote.profit_margin, 2) if quote.profit_margin else None,
        "roe": round(quote.roe, 2) if quote.roe else None,
        "debt_to_equity": round(quote.debt_to_equity, 2) if quote.debt_to_equity else None,
        # Analyst data
        "analyst_rating": quote.analyst_rating,
        "target_price": round(quote.target_price, 2) if quote.target_price else None,
        "num_analysts": quote.num_analysts,
        # Benchmark comparison
        "ibov_change_1d": round(quote.ibov_change_1d, 2) if quote.ibov_change_1d else None,
        "ibov_change_ytd": round(quote.ibov_change_ytd, 2) if quote.ibov_change_ytd else None,
        "sp500_change_1d": round(quote.sp500_change_1d, 2) if quote.sp500_change_1d else None,
        "sp500_change_ytd": round(quote.sp500_change_ytd, 2) if quote.sp500_change_ytd else None,
        "vs_ibov_1d": round(quote.vs_ibov_1d, 2) if quote.vs_ibov_1d else None,
        "vs_ibov_1m": round(quote.vs_ibov_1m, 2) if quote.vs_ibov_1m else None,
        "vs_ibov_ytd": round(quote.vs_ibov_ytd, 2) if quote.vs_ibov_ytd else None,
        "vs_sp500_1d": round(quote.vs_sp500_1d, 2) if quote.vs_sp500_1d else None,
        "vs_sp500_1m": round(quote.vs_sp500_1m, 2) if quote.vs_sp500_1m else None,
        "vs_sp500_ytd": round(quote.vs_sp500_ytd, 2) if quote.vs_sp500_ytd else None,
        # Trading signals
        "signal_golden_cross": quote.signal_golden_cross,
        "signal_death_cross": quote.signal_death_cross,
        "signal_rsi_oversold": quote.signal_rsi_oversold,
        "signal_rsi_overbought": quote.signal_rsi_overbought,
        "signal_52w_high": quote.signal_52w_high,
        "signal_52w_low": quote.signal_52w_low,
        "signal_volume_spike": quote.signal_volume_spike,
        "signal_summary": quote.signal_summary,
        # Volatility
        "volatility_30d": round(quote.volatility_30d, 2) if quote.volatility_30d else None,
        "avg_volume_20d": quote.avg_volume_20d,
        "volume_ratio": round(quote.volume_ratio, 2) if quote.volume_ratio else None,
        # News sentiment
        "news_sentiment_pt": round(quote.news_sentiment_pt, 3) if quote.news_sentiment_pt else None,
        "news_sentiment_en": round(quote.news_sentiment_en, 3) if quote.news_sentiment_en else None,
        "news_sentiment_combined": round(quote.news_sentiment_combined, 3) if quote.news_sentiment_combined else None,
        "news_count_pt": quote.news_count_pt,
        "news_count_en": quote.news_count_en,
        "news_headline_pt": quote.news_headline_pt,
        "news_headline_en": quote.news_headline_en,
        "news_sentiment_label": quote.news_sentiment_label,
        "data_cotacao": quote.quote_date.strftime("%Y-%m-%d"),
        "atualizado_em": quote.fetched_at.strftime("%Y-%m-%d %H:%M:%S")
    }


def export_to_csv(quote_date: Optional[date] = None, filename: Optional[str] = None) -> str:
    """
    Exporta cotaÃ§Ãµes para CSV
    
    Args:
        quote_date: Data especÃ­fica para exportar (None = mais recentes)
        filename: Nome do arquivo (None = gera automaticamente)
    
    Returns:
        Caminho do arquivo gerado
    """
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db, quote_date)
        
        if not quotes:
            print("âš ï¸ Nenhuma cotaÃ§Ã£o encontrada para exportar")
            return None
        
        # Gerar nome do arquivo
        if not filename:
            date_str = quote_date.strftime("%Y-%m-%d") if quote_date else datetime.now().strftime("%Y-%m-%d")
            filename = f"cotacoes_{date_str}.csv"
        
        filepath = os.path.join(EXPORTS_PATH, filename)
        
        # Criar diretÃ³rio se nÃ£o existir
        os.makedirs(EXPORTS_PATH, exist_ok=True)
        
        # Escrever CSV
        rows = [format_quote_row(q) for q in quotes]
        
        # Ordenar por setor e ticker
        rows.sort(key=lambda x: (x["setor"], x["ticker"]))
        
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=rows[0].keys())
            writer.writeheader()
            writer.writerows(rows)
        
        print(f"âœ… CSV exportado: {filepath} ({len(rows)} registros)")
        return filepath
        
    finally:
        db.close()


def export_to_json(quote_date: Optional[date] = None, filename: Optional[str] = None) -> str:
    """
    Exporta cotaÃ§Ãµes para JSON
    
    Args:
        quote_date: Data especÃ­fica para exportar (None = mais recentes)
        filename: Nome do arquivo (None = gera automaticamente)
    
    Returns:
        Caminho do arquivo gerado
    """
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db, quote_date)
        
        if not quotes:
            print("âš ï¸ Nenhuma cotaÃ§Ã£o encontrada para exportar")
            return None
        
        # Gerar nome do arquivo
        if not filename:
            date_str = quote_date.strftime("%Y-%m-%d") if quote_date else datetime.now().strftime("%Y-%m-%d")
            filename = f"cotacoes_{date_str}.json"
        
        filepath = os.path.join(EXPORTS_PATH, filename)
        
        # Criar diretÃ³rio se nÃ£o existir
        os.makedirs(EXPORTS_PATH, exist_ok=True)
        
        # Preparar dados
        rows = [format_quote_row(q) for q in quotes]
        rows.sort(key=lambda x: (x["setor"], x["ticker"]))
        
        data = {
            "data_exportacao": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total_ativos": len(rows),
            "cotacoes": rows
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSON exportado: {filepath} ({len(rows)} registros)")
        return filepath
        
    finally:
        db.close()


def print_summary():
    """Imprime um resumo das cotaÃ§Ãµes mais recentes com variaÃ§Ãµes"""
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db)
        
        if not quotes:
            print("âš ï¸ Nenhuma cotaÃ§Ã£o encontrada")
            return
        
        rows = [format_quote_row(q) for q in quotes]
        
        # Formatar variaÃ§Ãµes com cores ANSI e alinhamento correto
        def color_change(val):
            if val is None:
                return "     N/A"
            # Formato fixo de 8 caracteres: sinal + nÃºmero + %
            color = "\033[92m" if val >= 0 else "\033[91m"  # Verde/Vermelho
            reset = "\033[0m"
            if val >= 0:
                return f"{color}{val:>+7.1f}%{reset}"
            else:
                return f"{color}{val:>7.1f}%{reset}"
        
        def print_section(title, section_rows):
            """Imprime uma seÃ§Ã£o de ativos"""
            if not section_rows:
                return
            
            print(f"\n{'='*140}")
            print(f"  {title}")
            print(f"{'='*140}")
            print(f"{'TICKER':<10} {'NOME':<20} {'BRL':>12} {'USD':>10} {'1D':>8} {'1W':>8} {'1M':>8} {'YTD':>8} {'5Y':>8} {'ALL':>8}")
            print("-"*140)
            
            current_sector = None
            for row in section_rows:
                if row["setor"] != current_sector:
                    current_sector = row["setor"]
                    print(f"\n--- {current_sector.upper()} ---")
                
                usd_str = f"{row['preco_usd']:>10.2f}" if row['preco_usd'] else "       N/A"
                
                print(f"{row['ticker']:<10} {row['nome'][:19]:<20} {row['preco_brl']:>12,.2f} {usd_str} "
                      f"{color_change(row['var_1d'])} {color_change(row['var_1w'])} "
                      f"{color_change(row['var_1m'])} {color_change(row['var_ytd'])} "
                      f"{color_change(row['var_5y'])} {color_change(row['var_all'])}")
        
        # Separar por tipo de ativo
        br_stocks = [r for r in rows if r["tipo"] == "stock"]
        us_stocks = [r for r in rows if r["tipo"] == "us_stock"]
        commodities = [r for r in rows if r["tipo"] == "commodity"]
        crypto = [r for r in rows if r["tipo"] == "crypto"]
        currency = [r for r in rows if r["tipo"] == "currency"]
        
        # Ordenar cada seÃ§Ã£o por setor e ticker
        for section in [br_stocks, us_stocks, commodities, crypto, currency]:
            section.sort(key=lambda x: (x["setor"], x["ticker"]))
        
        # Imprimir cada seÃ§Ã£o
        print_section("ğŸ‡§ğŸ‡· AÃ‡Ã•ES BRASILEIRAS (B3)", br_stocks)
        print_section("ğŸ‡ºğŸ‡¸ AÃ‡Ã•ES AMERICANAS (NYSE/NASDAQ)", us_stocks)
        print_section("ğŸ¥‡ COMMODITIES", commodities)
        print_section("â‚¿ CRIPTOMOEDAS", crypto)
        print_section("ğŸ’± CÃ‚MBIO", currency)
        
        print(f"\n{'='*140}")
        print(f"Total de ativos: {len(rows)} | ğŸ‡§ğŸ‡· Brasil: {len(br_stocks)} | ğŸ‡ºğŸ‡¸ EUA: {len(us_stocks)} | "
              f"Commodities: {len(commodities)} | Crypto: {len(crypto)}")
        print("Legenda: 1D = Dia anterior | 1W = 1 semana | 1M = 1 mÃªs | YTD = Ano atÃ© a data | 5Y = 5 anos | ALL = Desde o inÃ­cio")
        print("="*140 + "\n")
        
    finally:
        db.close()


def print_ai_analysis():
    """Imprime anÃ¡lise detalhada com dados fundamentais para AI"""
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db)
        
        if not quotes:
            print("âš ï¸ Nenhuma cotaÃ§Ã£o encontrada")
            return
        
        rows = [format_quote_row(q) for q in quotes]
        
        def format_rating(rating):
            if not rating:
                return "    N/A"
            colors = {"buy": "\033[92m", "strong_buy": "\033[92m", 
                      "hold": "\033[93m", "sell": "\033[91m", "strong_sell": "\033[91m"}
            color = colors.get(rating, "")
            return f"{color}{rating:>7}\033[0m"
        
        def format_rsi(val):
            if val is None:
                return "   N/A"
            color = "\033[91m" if val > 70 else ("\033[92m" if val < 30 else "")
            return f"{color}{val:>5.0f}\033[0m"
        
        def format_pct(val, invert=False):
            if val is None:
                return "     N/A"
            color = "\033[92m" if (val >= 0) != invert else "\033[91m"
            return f"{color}{val:>+7.1f}%\033[0m"
        
        def format_signal(summary):
            if not summary:
                return "  N/A  "
            colors = {"bullish": "\033[92m", "bearish": "\033[91m", "neutral": "\033[93m"}
            emoji = {"bullish": "ğŸ“ˆ", "bearish": "ğŸ“‰", "neutral": "â–"}
            color = colors.get(summary, "")
            icon = emoji.get(summary, "")
            return f"{color}{icon}{summary[:4]:>4}\033[0m"
        
        print(f"\n{'='*180}")
        print("  ğŸ¤– AI INVESTMENT ANALYSIS - FUNDAMENTAL & TECHNICAL DATA")
        print(f"{'='*180}")
        print(f"{'TICKER':<8} {'NOME':<16} {'P/E':>7} {'BETA':>5} {'RSI':>5} {'vs52H':>8} {'vsIBOV':>8} {'vsSP500':>8} {'SIGNAL':>8} {'MA50':>5} {'MA200':>5} {'RATING':>8} {'VOL30D':>7}")
        print("-"*180)
        
        # Only show stocks (not commodities/crypto)
        stocks = [r for r in rows if r["tipo"] in ("stock", "us_stock")]
        stocks.sort(key=lambda x: (x["tipo"], x["setor"], x["ticker"]))
        
        current_type = None
        for row in stocks:
            if row["tipo"] != current_type:
                current_type = row["tipo"]
                label = "ğŸ‡§ğŸ‡· BRAZIL" if current_type == "stock" else "ğŸ‡ºğŸ‡¸ USA"
                print(f"\n{'='*40} {label} {'='*40}")
            
            pe = f"{row['pe_ratio']:>7.1f}" if row['pe_ratio'] else "    N/A"
            beta = f"{row['beta']:>5.2f}" if row['beta'] else "  N/A"
            ma50 = "  âœ“" if row['above_ma_50'] == 1 else ("  âœ—" if row['above_ma_50'] == 0 else " N/A")
            ma200 = "  âœ“" if row['above_ma_200'] == 1 else ("  âœ—" if row['above_ma_200'] == 0 else " N/A")
            vol30d = f"{row['volatility_30d']:>6.2f}%" if row['volatility_30d'] else "    N/A"
            
            # Use vs_ibov_ytd for Brazil, vs_sp500_ytd for US
            if row["tipo"] == "stock":
                vs_bench = format_pct(row['vs_ibov_ytd'])
            else:
                vs_bench = format_pct(row['vs_sp500_ytd'])
            
            print(f"{row['ticker']:<8} {row['nome'][:15]:<16} {pe} {beta} "
                  f"{format_rsi(row['rsi_14'])} {format_pct(row['pct_from_52w_high'], invert=True)} "
                  f"{format_pct(row['vs_ibov_ytd'])} {format_pct(row['vs_sp500_ytd'])} "
                  f"{format_signal(row['signal_summary'])} {ma50} {ma200} {format_rating(row['analyst_rating'])} {vol30d}")
        
        print(f"\n{'='*180}")
        print("Legend: vsIBOV/vsSP500 = YTD outperformance vs benchmark | SIGNAL = AI-detected signal (bullish/bearish/neutral)")
        print("        VOL30D = 30-day volatility | RSI = 14-day RSI (>70 overbought, <30 oversold) | vs52H = % from 52-week high")
        print("="*180 + "\n")
        
    finally:
        db.close()


def print_signals():
    """Imprime sinais de trading detectados"""
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db)
        
        if not quotes:
            print("âš ï¸ Nenhuma cotaÃ§Ã£o encontrada")
            return
        
        rows = [format_quote_row(q) for q in quotes]
        stocks = [r for r in rows if r["tipo"] in ("stock", "us_stock")]
        
        # Filter by signals
        bullish = [r for r in stocks if r.get('signal_summary') == 'bullish']
        bearish = [r for r in stocks if r.get('signal_summary') == 'bearish']
        oversold = [r for r in stocks if r.get('signal_rsi_oversold') == 1]
        overbought = [r for r in stocks if r.get('signal_rsi_overbought') == 1]
        at_52w_low = [r for r in stocks if r.get('signal_52w_low') == 1]
        at_52w_high = [r for r in stocks if r.get('signal_52w_high') == 1]
        volume_spike = [r for r in stocks if r.get('signal_volume_spike') == 1]
        golden_cross = [r for r in stocks if r.get('signal_golden_cross') == 1]
        
        print(f"\n{'='*80}")
        print("  ğŸš¦ TRADING SIGNALS DETECTED")
        print(f"{'='*80}")
        
        if bullish:
            print(f"\nğŸ“ˆ BULLISH SIGNALS ({len(bullish)} stocks):")
            for r in bullish[:10]:
                print(f"   {r['ticker']:<8} {r['nome'][:20]:<20} RSI: {r.get('rsi_14', 'N/A'):>5} | YTD: {r.get('var_ytd', 0):>+6.1f}%")
        
        if bearish:
            print(f"\nğŸ“‰ BEARISH SIGNALS ({len(bearish)} stocks):")
            for r in bearish[:10]:
                print(f"   {r['ticker']:<8} {r['nome'][:20]:<20} RSI: {r.get('rsi_14', 'N/A'):>5} | YTD: {r.get('var_ytd', 0):>+6.1f}%")
        
        if oversold:
            print(f"\nğŸŸ¢ RSI OVERSOLD (<30) - Potential buy ({len(oversold)} stocks):")
            for r in oversold:
                print(f"   {r['ticker']:<8} RSI: {r.get('rsi_14', 0):>5.0f}")
        
        if overbought:
            print(f"\nğŸ”´ RSI OVERBOUGHT (>70) - Potential sell ({len(overbought)} stocks):")
            for r in overbought:
                print(f"   {r['ticker']:<8} RSI: {r.get('rsi_14', 0):>5.0f}")
        
        if at_52w_low:
            print(f"\nâ¬‡ï¸ NEAR 52-WEEK LOW (within 5%) ({len(at_52w_low)} stocks):")
            for r in at_52w_low:
                print(f"   {r['ticker']:<8} {r['nome'][:20]:<20}")
        
        if at_52w_high:
            print(f"\nâ¬†ï¸ NEAR 52-WEEK HIGH (within 5%) ({len(at_52w_high)} stocks):")
            for r in at_52w_high:
                print(f"   {r['ticker']:<8} {r['nome'][:20]:<20}")
        
        if volume_spike:
            print(f"\nğŸ“Š VOLUME SPIKE (>2x average) ({len(volume_spike)} stocks):")
            for r in volume_spike:
                ratio = r.get('volume_ratio', 0)
                print(f"   {r['ticker']:<8} Volume: {ratio:>4.1f}x average")
        
        if golden_cross:
            print(f"\nâœ¨ GOLDEN CROSS (MA50 > MA200) ({len(golden_cross)} stocks):")
            for r in golden_cross[:10]:
                print(f"   {r['ticker']:<8} {r['nome'][:20]:<20}")
        
        print(f"\n{'='*80}\n")
        
    finally:
        db.close()


def print_news_sentiment():
    """Imprime anÃ¡lise de sentimento de notÃ­cias"""
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db)
        
        if not quotes:
            print("âš ï¸ Nenhuma cotaÃ§Ã£o encontrada")
            return
        
        rows = [format_quote_row(q) for q in quotes]
        stocks = [r for r in rows if r["tipo"] in ("stock", "us_stock")]
        
        # Filter by sentiment
        positive = [r for r in stocks if r.get('news_sentiment_label') == 'positive']
        negative = [r for r in stocks if r.get('news_sentiment_label') == 'negative']
        neutral = [r for r in stocks if r.get('news_sentiment_label') == 'neutral']
        
        # Sort by combined sentiment score
        positive.sort(key=lambda x: x.get('news_sentiment_combined', 0) or 0, reverse=True)
        negative.sort(key=lambda x: x.get('news_sentiment_combined', 0) or 0)
        
        # Separate Brazilian and US stocks
        br_positive = [r for r in positive if r["tipo"] == "stock"]
        us_positive = [r for r in positive if r["tipo"] == "us_stock"]
        br_negative = [r for r in negative if r["tipo"] == "stock"]
        us_negative = [r for r in negative if r["tipo"] == "us_stock"]
        
        def format_score(score):
            if score is None:
                return "  N/A"
            color = "\033[92m" if score >= 0.2 else ("\033[91m" if score <= -0.2 else "\033[93m")
            return f"{color}{score:>+.2f}\033[0m"
        
        def truncate(text, max_len=50):
            if not text:
                return ""
            return text[:max_len] + "..." if len(text) > max_len else text
        
        print(f"\n{'='*120}")
        print("  ğŸ“° NEWS SENTIMENT ANALYSIS")
        print(f"{'='*120}")
        
        # Brazilian stocks with positive sentiment
        if br_positive:
            print(f"\nğŸ‡§ğŸ‡· BRAZIL - ğŸŸ¢ POSITIVE SENTIMENT ({len(br_positive)} stocks):")
            for r in br_positive[:8]:
                pt_score = format_score(r.get('news_sentiment_pt'))
                en_score = format_score(r.get('news_sentiment_en'))
                combined = format_score(r.get('news_sentiment_combined'))
                pt_count = r.get('news_count_pt', 0) or 0
                en_count = r.get('news_count_en', 0) or 0
                headline = truncate(r.get('news_headline_pt') or r.get('news_headline_en', ''))
                print(f"   {r['ticker']:<8} {r['nome'][:16]:<16} PT: {pt_score} ({pt_count}) | EN: {en_score} ({en_count}) | Combined: {combined}")
                if headline:
                    print(f"            \033[90m\"{headline}\"\033[0m")
        
        # Brazilian stocks with negative sentiment
        if br_negative:
            print(f"\nğŸ‡§ğŸ‡· BRAZIL - ğŸ”´ NEGATIVE SENTIMENT ({len(br_negative)} stocks):")
            for r in br_negative[:8]:
                pt_score = format_score(r.get('news_sentiment_pt'))
                en_score = format_score(r.get('news_sentiment_en'))
                combined = format_score(r.get('news_sentiment_combined'))
                pt_count = r.get('news_count_pt', 0) or 0
                en_count = r.get('news_count_en', 0) or 0
                headline = truncate(r.get('news_headline_pt') or r.get('news_headline_en', ''))
                print(f"   {r['ticker']:<8} {r['nome'][:16]:<16} PT: {pt_score} ({pt_count}) | EN: {en_score} ({en_count}) | Combined: {combined}")
                if headline:
                    print(f"            \033[90m\"{headline}\"\033[0m")
        
        # US stocks with positive sentiment
        if us_positive:
            print(f"\nğŸ‡ºğŸ‡¸ USA - ğŸŸ¢ POSITIVE SENTIMENT ({len(us_positive)} stocks):")
            for r in us_positive[:8]:
                en_score = format_score(r.get('news_sentiment_en'))
                en_count = r.get('news_count_en', 0) or 0
                headline = truncate(r.get('news_headline_en', ''))
                print(f"   {r['ticker']:<8} {r['nome'][:16]:<16} EN: {en_score} ({en_count} articles)")
                if headline:
                    print(f"            \033[90m\"{headline}\"\033[0m")
        
        # US stocks with negative sentiment
        if us_negative:
            print(f"\nğŸ‡ºğŸ‡¸ USA - ğŸ”´ NEGATIVE SENTIMENT ({len(us_negative)} stocks):")
            for r in us_negative[:8]:
                en_score = format_score(r.get('news_sentiment_en'))
                en_count = r.get('news_count_en', 0) or 0
                headline = truncate(r.get('news_headline_en', ''))
                print(f"   {r['ticker']:<8} {r['nome'][:16]:<16} EN: {en_score} ({en_count} articles)")
                if headline:
                    print(f"            \033[90m\"{headline}\"\033[0m")
        
        # Summary
        total_with_news = len([r for r in stocks if r.get('news_count_pt', 0) or r.get('news_count_en', 0)])
        print(f"\n{'='*120}")
        print(f"Summary: {len(positive)} positive | {len(negative)} negative | {len(neutral)} neutral | {total_with_news} stocks with news")
        print("Score range: -1.0 (very negative) to +1.0 (very positive) | Threshold: Â±0.2 for classification")
        print("Brazilian stocks: 60% PT weight + 40% EN weight for combined score")
        print(f"{'='*120}\n")
        
    finally:
        db.close()


def export_ai_json(filename: Optional[str] = None) -> str:
    """
    Exporta dados em formato otimizado para anÃ¡lise de AI
    """
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db)
        
        if not quotes:
            print("âš ï¸ Nenhuma cotaÃ§Ã£o encontrada para exportar")
            return None
        
        if not filename:
            filename = f"ai_analysis_{datetime.now().strftime('%Y-%m-%d')}.json"
        
        filepath = os.path.join(EXPORTS_PATH, filename)
        os.makedirs(EXPORTS_PATH, exist_ok=True)
        
        rows = [format_quote_row(q) for q in quotes]
        
        # Structure for AI consumption
        data = {
            "metadata": {
                "generated_at": datetime.now().isoformat(),
                "total_assets": len(rows),
                "data_version": "2.0",
                "description": "B3 and US stock data with fundamentals for AI analysis"
            },
            "market_summary": {
                "brazil_stocks": len([r for r in rows if r["tipo"] == "stock"]),
                "us_stocks": len([r for r in rows if r["tipo"] == "us_stock"]),
                "commodities": len([r for r in rows if r["tipo"] == "commodity"]),
                "crypto": len([r for r in rows if r["tipo"] == "crypto"]),
            },
            "assets": rows
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… AI JSON exportado: {filepath}")
        return filepath
        
    finally:
        db.close()


def generate_report_data() -> dict:
    """
    Gera dados consolidados para relatÃ³rios (human e AI).
    Retorna um dicionÃ¡rio com todos os dados processados.
    """
    db = SessionLocal()
    
    try:
        quotes = get_latest_quotes(db)
        
        if not quotes:
            return None
        
        rows = [format_quote_row(q) for q in quotes]
        
        # Separate by type
        br_stocks = [r for r in rows if r["tipo"] == "stock"]
        us_stocks = [r for r in rows if r["tipo"] == "us_stock"]
        commodities = [r for r in rows if r["tipo"] == "commodity"]
        crypto = [r for r in rows if r["tipo"] == "crypto"]
        all_stocks = br_stocks + us_stocks
        
        # Top movers (1D)
        stocks_with_1d = [r for r in all_stocks if r.get("var_1d") is not None]
        top_gainers = sorted(stocks_with_1d, key=lambda x: x.get("var_1d", 0), reverse=True)[:10]
        top_losers = sorted(stocks_with_1d, key=lambda x: x.get("var_1d", 0))[:10]
        
        # Signals
        bullish = [r for r in all_stocks if r.get('signal_summary') == 'bullish']
        bearish = [r for r in all_stocks if r.get('signal_summary') == 'bearish']
        oversold = [r for r in all_stocks if r.get('signal_rsi_oversold') == 1]
        overbought = [r for r in all_stocks if r.get('signal_rsi_overbought') == 1]
        near_52w_high = [r for r in all_stocks if r.get('signal_52w_high') == 1]
        near_52w_low = [r for r in all_stocks if r.get('signal_52w_low') == 1]
        volume_spike = [r for r in all_stocks if r.get('signal_volume_spike') == 1]
        golden_cross = [r for r in all_stocks if r.get('signal_golden_cross') == 1]
        
        # News sentiment
        positive_news = sorted(
            [r for r in all_stocks if r.get('news_sentiment_label') == 'positive'],
            key=lambda x: x.get('news_sentiment_combined', 0) or 0,
            reverse=True
        )
        negative_news = sorted(
            [r for r in all_stocks if r.get('news_sentiment_label') == 'negative'],
            key=lambda x: x.get('news_sentiment_combined', 0) or 0
        )
        
        # Benchmark data (from first stock that has it)
        ibov_ytd = None
        sp500_ytd = None
        for r in rows:
            if r.get("ibov_change_ytd") and ibov_ytd is None:
                ibov_ytd = r["ibov_change_ytd"]
            if r.get("sp500_change_ytd") and sp500_ytd is None:
                sp500_ytd = r["sp500_change_ytd"]
            if ibov_ytd and sp500_ytd:
                break
        
        # USD/BRL (from currency or calculate from stocks)
        usd_brl = None
        for r in rows:
            if r["tipo"] == "currency":
                usd_brl = r["preco_brl"]
                break
        
        return {
            "generated_at": datetime.now(),
            "total_assets": len(rows),
            "counts": {
                "brazil_stocks": len(br_stocks),
                "us_stocks": len(us_stocks),
                "commodities": len(commodities),
                "crypto": len(crypto),
            },
            "market_context": {
                "ibov_ytd": ibov_ytd,
                "sp500_ytd": sp500_ytd,
                "usd_brl": usd_brl,
            },
            "top_movers": {
                "gainers": top_gainers,
                "losers": top_losers,
            },
            "signals": {
                "bullish": bullish,
                "bearish": bearish,
                "oversold": oversold,
                "overbought": overbought,
                "near_52w_high": near_52w_high,
                "near_52w_low": near_52w_low,
                "volume_spike": volume_spike,
                "golden_cross": golden_cross,
            },
            "news_sentiment": {
                "positive": positive_news,
                "negative": negative_news,
            },
            "all_data": rows,
        }
        
    finally:
        db.close()


def export_human_report(filename: Optional[str] = None) -> str:
    """
    Exporta relatÃ³rio em Markdown para leitura humana.
    """
    data = generate_report_data()
    
    if not data:
        print("âš ï¸ Nenhum dado para gerar relatÃ³rio")
        return None
    
    if not filename:
        filename = f"report_{datetime.now().strftime('%Y-%m-%d')}.md"
    
    filepath = os.path.join(EXPORTS_PATH, filename)
    os.makedirs(EXPORTS_PATH, exist_ok=True)
    
    lines = []
    
    # Header
    lines.append(f"# ğŸ“ˆ B3 Tracker Report - {data['generated_at'].strftime('%Y-%m-%d %H:%M')}")
    lines.append("")
    
    # Market Summary
    lines.append("## ğŸ“Š Market Summary")
    lines.append("")
    lines.append(f"- **Total de ativos**: {data['total_assets']}")
    lines.append(f"  - ğŸ‡§ğŸ‡· Brasil: {data['counts']['brazil_stocks']}")
    lines.append(f"  - ğŸ‡ºğŸ‡¸ EUA: {data['counts']['us_stocks']}")
    lines.append(f"  - ğŸ¥‡ Commodities: {data['counts']['commodities']}")
    lines.append(f"  - â‚¿ Crypto: {data['counts']['crypto']}")
    lines.append("")
    
    ctx = data['market_context']
    if ctx['ibov_ytd'] or ctx['sp500_ytd']:
        lines.append("### Benchmarks YTD")
        if ctx['ibov_ytd']:
            lines.append(f"- **IBOV**: {ctx['ibov_ytd']:+.1f}%")
        if ctx['sp500_ytd']:
            lines.append(f"- **S&P 500**: {ctx['sp500_ytd']:+.1f}%")
        if ctx['usd_brl']:
            lines.append(f"- **USD/BRL**: R$ {ctx['usd_brl']:.2f}")
        lines.append("")
    
    # Top Movers
    lines.append("## ğŸ”¥ Top Movers (1D)")
    lines.append("")
    
    lines.append("### ğŸ“ˆ Maiores Altas")
    lines.append("| Ticker | Nome | VariaÃ§Ã£o 1D |")
    lines.append("|--------|------|-------------|")
    for r in data['top_movers']['gainers'][:5]:
        lines.append(f"| {r['ticker']} | {r['nome'][:20]} | {r['var_1d']:+.2f}% |")
    lines.append("")
    
    lines.append("### ğŸ“‰ Maiores Quedas")
    lines.append("| Ticker | Nome | VariaÃ§Ã£o 1D |")
    lines.append("|--------|------|-------------|")
    for r in data['top_movers']['losers'][:5]:
        lines.append(f"| {r['ticker']} | {r['nome'][:20]} | {r['var_1d']:+.2f}% |")
    lines.append("")
    
    # Trading Signals
    lines.append("## ğŸš¦ Trading Signals")
    lines.append("")
    
    signals = data['signals']
    
    if signals['bullish']:
        lines.append(f"### ğŸ“ˆ Bullish ({len(signals['bullish'])} stocks)")
        tickers = ", ".join([r['ticker'] for r in signals['bullish'][:15]])
        lines.append(f"{tickers}")
        lines.append("")
    
    if signals['bearish']:
        lines.append(f"### ğŸ“‰ Bearish ({len(signals['bearish'])} stocks)")
        tickers = ", ".join([r['ticker'] for r in signals['bearish'][:15]])
        lines.append(f"{tickers}")
        lines.append("")
    
    if signals['oversold']:
        lines.append(f"### ğŸŸ¢ RSI Oversold (<30) - Potencial compra")
        for r in signals['oversold'][:5]:
            lines.append(f"- **{r['ticker']}** ({r['nome'][:20]}) - RSI: {r['rsi_14']:.0f}")
        lines.append("")
    
    if signals['overbought']:
        lines.append(f"### ğŸ”´ RSI Overbought (>70) - Potencial venda")
        for r in signals['overbought'][:5]:
            lines.append(f"- **{r['ticker']}** ({r['nome'][:20]}) - RSI: {r['rsi_14']:.0f}")
        lines.append("")
    
    if signals['near_52w_high']:
        lines.append(f"### â¬†ï¸ PrÃ³ximo da MÃ¡xima 52 semanas ({len(signals['near_52w_high'])} stocks)")
        tickers = ", ".join([r['ticker'] for r in signals['near_52w_high'][:10]])
        lines.append(f"{tickers}")
        lines.append("")
    
    if signals['near_52w_low']:
        lines.append(f"### â¬‡ï¸ PrÃ³ximo da MÃ­nima 52 semanas ({len(signals['near_52w_low'])} stocks)")
        tickers = ", ".join([r['ticker'] for r in signals['near_52w_low'][:10]])
        lines.append(f"{tickers}")
        lines.append("")
    
    # News Sentiment
    lines.append("## ğŸ“° News Sentiment")
    lines.append("")
    
    news = data['news_sentiment']
    
    if news['positive']:
        lines.append(f"### ğŸŸ¢ Sentimento Positivo ({len(news['positive'])} stocks)")
        for r in news['positive'][:5]:
            score = r.get('news_sentiment_combined', 0) or 0
            headline = r.get('news_headline_pt') or r.get('news_headline_en', '')
            headline = headline[:60] + "..." if len(headline) > 60 else headline
            lines.append(f"- **{r['ticker']}** (score: {score:+.2f})")
            if headline:
                lines.append(f"  - *\"{headline}\"*")
        lines.append("")
    
    if news['negative']:
        lines.append(f"### ğŸ”´ Sentimento Negativo ({len(news['negative'])} stocks)")
        for r in news['negative'][:5]:
            score = r.get('news_sentiment_combined', 0) or 0
            headline = r.get('news_headline_pt') or r.get('news_headline_en', '')
            headline = headline[:60] + "..." if len(headline) > 60 else headline
            lines.append(f"- **{r['ticker']}** (score: {score:+.2f})")
            if headline:
                lines.append(f"  - *\"{headline}\"*")
        lines.append("")
    
    # Footer
    lines.append("---")
    lines.append(f"*Gerado em {data['generated_at'].strftime('%Y-%m-%d %H:%M:%S')} por B3 Tracker*")
    
    # Write file
    with open(filepath, 'w', encoding='utf-8') as f:
        f.write("\n".join(lines))
    
    print(f"âœ… RelatÃ³rio Human exportado: {filepath}")
    return filepath


def export_ai_report(filename: Optional[str] = None) -> str:
    """
    Exporta relatÃ³rio JSON estruturado para consumo por AI/LLM.
    """
    data = generate_report_data()
    
    if not data:
        print("âš ï¸ Nenhum dado para gerar relatÃ³rio")
        return None
    
    if not filename:
        filename = f"ai_report_{datetime.now().strftime('%Y-%m-%d')}.json"
    
    filepath = os.path.join(EXPORTS_PATH, filename)
    os.makedirs(EXPORTS_PATH, exist_ok=True)
    
    # Build AI-optimized structure
    def extract_ticker_info(items, fields=None):
        """Extract minimal info for AI consumption"""
        if fields is None:
            fields = ['ticker', 'nome', 'var_1d', 'var_ytd', 'rsi_14', 'signal_summary']
        return [{k: r.get(k) for k in fields if k in r} for r in items]
    
    report = {
        "metadata": {
            "report_type": "daily_market_summary",
            "generated_at": data['generated_at'].isoformat(),
            "total_assets": data['total_assets'],
            "version": "1.0",
        },
        "market_context": {
            "ibov_ytd_pct": data['market_context']['ibov_ytd'],
            "sp500_ytd_pct": data['market_context']['sp500_ytd'],
            "usd_brl": data['market_context']['usd_brl'],
            "asset_counts": data['counts'],
        },
        "signals_summary": {
            "bullish_count": len(data['signals']['bullish']),
            "bearish_count": len(data['signals']['bearish']),
            "bullish_tickers": [r['ticker'] for r in data['signals']['bullish']],
            "bearish_tickers": [r['ticker'] for r in data['signals']['bearish']],
            "rsi_oversold": [{"ticker": r['ticker'], "rsi": r['rsi_14']} for r in data['signals']['oversold']],
            "rsi_overbought": [{"ticker": r['ticker'], "rsi": r['rsi_14']} for r in data['signals']['overbought']],
            "near_52w_high": [r['ticker'] for r in data['signals']['near_52w_high']],
            "near_52w_low": [r['ticker'] for r in data['signals']['near_52w_low']],
            "volume_spike": [r['ticker'] for r in data['signals']['volume_spike']],
            "golden_cross_count": len(data['signals']['golden_cross']),
        },
        "top_movers": {
            "gainers_1d": [
                {"ticker": r['ticker'], "name": r['nome'], "change_1d": r['var_1d']}
                for r in data['top_movers']['gainers'][:10]
            ],
            "losers_1d": [
                {"ticker": r['ticker'], "name": r['nome'], "change_1d": r['var_1d']}
                for r in data['top_movers']['losers'][:10]
            ],
        },
        "news_sentiment": {
            "positive_count": len(data['news_sentiment']['positive']),
            "negative_count": len(data['news_sentiment']['negative']),
            "positive": [
                {
                    "ticker": r['ticker'],
                    "score": r.get('news_sentiment_combined'),
                    "headline": (r.get('news_headline_pt') or r.get('news_headline_en', ''))[:100]
                }
                for r in data['news_sentiment']['positive'][:10]
            ],
            "negative": [
                {
                    "ticker": r['ticker'],
                    "score": r.get('news_sentiment_combined'),
                    "headline": (r.get('news_headline_pt') or r.get('news_headline_en', ''))[:100]
                }
                for r in data['news_sentiment']['negative'][:10]
            ],
        },
        "actionable_insights": {
            "potential_buys": [
                r['ticker'] for r in data['signals']['oversold']
            ] + [
                r['ticker'] for r in data['signals']['near_52w_low']
            ],
            "potential_sells": [
                r['ticker'] for r in data['signals']['overbought']
            ],
            "momentum_stocks": [
                r['ticker'] for r in data['signals']['bullish'] 
                if r.get('var_ytd', 0) and r['var_ytd'] > 20
            ][:10],
        },
        "full_data": data['all_data'],
    }
    
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"âœ… RelatÃ³rio AI exportado: {filepath}")
    return filepath


def generate_reports() -> tuple:
    """
    Gera ambos os relatÃ³rios (Human e AI).
    Retorna tupla com os caminhos dos arquivos.
    """
    human_path = export_human_report()
    ai_path = export_ai_report()
    return human_path, ai_path


if __name__ == "__main__":
    from database import init_db
    init_db()
    
    print("\nğŸ“Š Exportando cotaÃ§Ãµes...\n")
    export_to_csv()
    export_to_json()
    export_ai_json()
    print_summary()
    print_ai_analysis()
    print_signals()
    print_news_sentiment()
